# bspt
Test excersise for the ETL/ML by V.Churuksaeva (chu.vv@mail.ru).


Для получения результата требуется скопировать в отдельную директорию питон-скрипт sflow-analysis.py, реализующий решение задачи, GeoLite2-Country.mmdb - файл данных Geolite2 Country и скрипт для запуска run.sh. *.csv, содержащий данные в формате sFlow, которые требуется проанализировать, указывается в файле run.sh в качестве третьего параметра командной строки при запуске решения. 
run.sh может вызывать скрипт spark-submit для запуска sflow-analysis.py или запускать sflow-analysis.py с помощью python. 
В данный момент настроен локальный запуск скрипта на 4 потоках для анализа тестового набора данных из файла one.csv, содержащего короткий набор данных sflow для тестирования скрипта. Данный файл также находится в репозитории.
Параметры для конфигурации SparkContext как и имя *.csv файла с исходными данными передаются через параметры командной строки. Стандартный поток вывода перенаправляется в tech_out.txt

В результате работы программы формируются файлы:
out_ip_list.txt, содержащий сумму размеров пакетов для каждого ip адреса,
out_count_list.txt - сумму размеров пакетов для каждой страны и
countries.png – гистограмма, показывающая распределение трафика по странам.
В файл tech_out.txt печатается время выполнения расчетов и работы скрипта в целом. 
В репозитории находятся файлы, полученные в результате анализа предоставленного Вами тестового набора данных sflow-0118.csv (http://dispatcher.netpoint-dc.com/images/sflow/slow-sample.csv.tgz).
В файле report.pdf содержится краткий отчет по корректному подсчету трафика с помощью sFlow и результаты анализа эффективности параллельной версии скрипта.
